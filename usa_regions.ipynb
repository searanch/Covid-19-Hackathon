{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting Covid-19 Data into Regions and SubRegions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NorthEast Region:\n",
    "New England (Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>tests_positive</th>\n",
       "      <th>tests_negative</th>\n",
       "      <th>tests_pending</th>\n",
       "      <th>tests</th>\n",
       "      <th>patients_icu</th>\n",
       "      <th>patients_hosp</th>\n",
       "      <th>patients_vent</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>42.913397</td>\n",
       "      <td>-75.596272</td>\n",
       "      <td>7/1/2020</td>\n",
       "      <td>398770</td>\n",
       "      <td>31791</td>\n",
       "      <td>394079.0</td>\n",
       "      <td>3577569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3971648.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>70590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>42.913397</td>\n",
       "      <td>-75.596272</td>\n",
       "      <td>7/2/2020</td>\n",
       "      <td>399642</td>\n",
       "      <td>31814</td>\n",
       "      <td>394954.0</td>\n",
       "      <td>3646639.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4041593.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>70698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>42.913397</td>\n",
       "      <td>-75.596272</td>\n",
       "      <td>7/3/2020</td>\n",
       "      <td>400561</td>\n",
       "      <td>31836</td>\n",
       "      <td>395872.0</td>\n",
       "      <td>3712113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4107985.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>42.913397</td>\n",
       "      <td>-75.596272</td>\n",
       "      <td>7/4/2020</td>\n",
       "      <td>401286</td>\n",
       "      <td>31860</td>\n",
       "      <td>396598.0</td>\n",
       "      <td>3773790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4170388.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>70877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>42.913397</td>\n",
       "      <td>-75.596272</td>\n",
       "      <td>7/5/2020</td>\n",
       "      <td>401822</td>\n",
       "      <td>31895</td>\n",
       "      <td>397131.0</td>\n",
       "      <td>3836672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4233803.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>70968.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_fips state_name        lat       long      date   cases  deaths  \\\n",
       "0          36   New York  42.913397 -75.596272  7/1/2020  398770   31791   \n",
       "1          36   New York  42.913397 -75.596272  7/2/2020  399642   31814   \n",
       "2          36   New York  42.913397 -75.596272  7/3/2020  400561   31836   \n",
       "3          36   New York  42.913397 -75.596272  7/4/2020  401286   31860   \n",
       "4          36   New York  42.913397 -75.596272  7/5/2020  401822   31895   \n",
       "\n",
       "   tests_positive  tests_negative  tests_pending      tests  patients_icu  \\\n",
       "0        394079.0       3577569.0            NaN  3971648.0         226.0   \n",
       "1        394954.0       3646639.0            NaN  4041593.0         209.0   \n",
       "2        395872.0       3712113.0            NaN  4107985.0         188.0   \n",
       "3        396598.0       3773790.0            NaN  4170388.0         190.0   \n",
       "4        397131.0       3836672.0            NaN  4233803.0         178.0   \n",
       "\n",
       "   patients_hosp  patients_vent  recovered  \n",
       "0          879.0          139.0    70590.0  \n",
       "1          878.0          129.0    70698.0  \n",
       "2          857.0          125.0    70794.0  \n",
       "3          844.0          119.0    70877.0  \n",
       "4          832.0          116.0    70968.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load enigma dataset.\n",
    "usa = pd.read_csv('enigma_Aug_8_2020.csv')\n",
    "usa.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Pandas Profile to Learn more about Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProfileReport' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ba1f65de78d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Pandas Profiling Report\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"explore_enigma_data.html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ProfileReport' is not defined"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(usa, title=\"Pandas Profiling Report\")\n",
    "profile\n",
    "profile.to_file(\"explore_enigma_data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>tests_positive</th>\n",
       "      <th>tests_negative</th>\n",
       "      <th>tests_pending</th>\n",
       "      <th>tests</th>\n",
       "      <th>patients_icu</th>\n",
       "      <th>patients_hosp</th>\n",
       "      <th>patients_vent</th>\n",
       "      <th>recovered</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>563</td>\n",
       "      <td>40</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>35.590051</td>\n",
       "      <td>-97.486815</td>\n",
       "      <td>6/19/2020</td>\n",
       "      <td>9706</td>\n",
       "      <td>367</td>\n",
       "      <td>9706.0</td>\n",
       "      <td>264872.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274578.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7212.0</td>\n",
       "      <td>2020-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4694</td>\n",
       "      <td>12</td>\n",
       "      <td>Florida</td>\n",
       "      <td>28.457430</td>\n",
       "      <td>-82.409148</td>\n",
       "      <td>5/7/2020</td>\n",
       "      <td>38820</td>\n",
       "      <td>1599</td>\n",
       "      <td>38828.0</td>\n",
       "      <td>454122.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>492950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6619</td>\n",
       "      <td>26</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>44.844177</td>\n",
       "      <td>-85.660491</td>\n",
       "      <td>4/19/2020</td>\n",
       "      <td>31349</td>\n",
       "      <td>2389</td>\n",
       "      <td>37557.0</td>\n",
       "      <td>89758.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127315.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>3237.0</td>\n",
       "      <td>2020-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7290</td>\n",
       "      <td>31</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>41.543305</td>\n",
       "      <td>-99.811865</td>\n",
       "      <td>2/20/2020</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7770</td>\n",
       "      <td>34</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>40.107274</td>\n",
       "      <td>-74.665201</td>\n",
       "      <td>3/29/2020</td>\n",
       "      <td>13386</td>\n",
       "      <td>161</td>\n",
       "      <td>13386.0</td>\n",
       "      <td>22216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35602.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state_fips  state_name        lat       long       date  cases  deaths  \\\n",
       "563           40    Oklahoma  35.590051 -97.486815  6/19/2020   9706     367   \n",
       "4694          12     Florida  28.457430 -82.409148   5/7/2020  38820    1599   \n",
       "6619          26    Michigan  44.844177 -85.660491  4/19/2020  31349    2389   \n",
       "7290          31    Nebraska  41.543305 -99.811865  2/20/2020     11       0   \n",
       "7770          34  New Jersey  40.107274 -74.665201  3/29/2020  13386     161   \n",
       "\n",
       "      tests_positive  tests_negative  tests_pending     tests  patients_icu  \\\n",
       "563           9706.0        264872.0            NaN  274578.0          96.0   \n",
       "4694         38828.0        454122.0         1499.0  492950.0           NaN   \n",
       "6619         37557.0         89758.0            NaN  127315.0        1344.0   \n",
       "7290             NaN             NaN            NaN       NaN           NaN   \n",
       "7770         13386.0         22216.0            NaN   35602.0           NaN   \n",
       "\n",
       "      patients_hosp  patients_vent  recovered   datetime  \n",
       "563           211.0            NaN     7212.0 2020-06-19  \n",
       "4694            NaN            NaN        NaN 2020-05-07  \n",
       "6619         3403.0         1115.0     3237.0 2020-04-19  \n",
       "7290            NaN            NaN        NaN 2020-02-20  \n",
       "7770         2000.0            NaN        NaN 2020-03-29  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first datetime conversion\n",
    "usa['datetime'] = pd.to_datetime(usa['date'])\n",
    "#usa[\"day\"] = usa['datetime'].map(lambda x: x.day)\n",
    "#usa[\"month\"] = usa['datetime'].map(lambda x: x.month)\n",
    "#usa[\"year\"] = usa['datetime'].map(lambda x: x.year)\n",
    "#usa.sample(5)\n",
    "usa.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NorthEast Region:\n",
    "New England Divsion 1 (Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>tests_positive</th>\n",
       "      <th>tests_negative</th>\n",
       "      <th>tests_pending</th>\n",
       "      <th>tests</th>\n",
       "      <th>patients_icu</th>\n",
       "      <th>patients_hosp</th>\n",
       "      <th>patients_vent</th>\n",
       "      <th>recovered</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.597419</td>\n",
       "      <td>-71.527272</td>\n",
       "      <td>3/1/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>901</td>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.597419</td>\n",
       "      <td>-71.527272</td>\n",
       "      <td>3/2/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>902</td>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.597419</td>\n",
       "      <td>-71.527272</td>\n",
       "      <td>3/3/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.597419</td>\n",
       "      <td>-71.527272</td>\n",
       "      <td>3/4/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>904</td>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.597419</td>\n",
       "      <td>-71.527272</td>\n",
       "      <td>3/5/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_fips    state_name        lat       long      date  cases  deaths  \\\n",
       "900          44  Rhode Island  41.597419 -71.527272  3/1/2020      2       0   \n",
       "901          44  Rhode Island  41.597419 -71.527272  3/2/2020      2       0   \n",
       "902          44  Rhode Island  41.597419 -71.527272  3/3/2020      2       0   \n",
       "903          44  Rhode Island  41.597419 -71.527272  3/4/2020      2       0   \n",
       "904          44  Rhode Island  41.597419 -71.527272  3/5/2020      2       0   \n",
       "\n",
       "     tests_positive  tests_negative  tests_pending  tests  patients_icu  \\\n",
       "900             2.0             2.0            NaN    4.0           NaN   \n",
       "901             2.0             3.0            NaN    5.0           NaN   \n",
       "902             2.0             5.0            NaN    7.0           NaN   \n",
       "903             2.0            15.0            NaN   17.0           NaN   \n",
       "904             3.0            19.0            NaN   22.0           NaN   \n",
       "\n",
       "     patients_hosp  patients_vent  recovered   datetime  \n",
       "900            NaN            NaN        NaN 2020-03-01  \n",
       "901            NaN            NaN        NaN 2020-03-02  \n",
       "902            NaN            NaN        NaN 2020-03-03  \n",
       "903            NaN            NaN        NaN 2020-03-04  \n",
       "904            NaN            NaN        NaN 2020-03-05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created DF based New Englend Divsion\n",
    "new_englend = usa[(usa['state_name']==\"Connecticut\") | (usa['state_name'] == 'Maine') |\n",
    "                      (usa['state_name'] == 'Massachusetts') | (usa['state_name'] == 'New Hampshire') | \\\n",
    "                     (usa['state_name']=='Rhode Island')| (usa['state_name'] =='Vermont')]\n",
    "new_englend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO ADD DAILY DIVISION TALLY FOR NEW ENGLEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing case count for New Englend Divsion\n",
    "# Groupby to consolidate cases by entire region\n",
    "NE_group = new_englend.groupby([\"datetime\"])\n",
    "NE_sum = NE_group[\"cases\"].sum()\n",
    "\n",
    "# merge output of above groupbys to create new df\n",
    "NE_new =new_englend.merge(mid_sum, on = \"datetime\")\n",
    "# Rename columns and sort by date\n",
    "NE_new = NE_new.rename(columns={\"cases_y\": \"reg_sum_cases\"}) \n",
    "NE_new.sort_values(by =\"datetime\")\n",
    "\n",
    "# Perform groupby operations to sum cases by day\n",
    "NE_tally =NE_new.groupby(['date', 'reg_sum_cases']).sum()\n",
    "NE_tally = NE_tally.reset_index()\n",
    "NE_tally.head(5)\n",
    "\n",
    "# now finsh date time conversion\n",
    "NE_tally['datetime'] = pd.to_datetime(NE_tally['date'])\n",
    "NE_tally[\"day\"] = NE_tally['datetime'].map(lambda x: x.day)\n",
    "NE_tally[\"month\"] = NE_tally['datetime'].map(lambda x: x.month)\n",
    "NE_tally[\"year\"] = NE_tally['datetime'].map(lambda x: x.year)\n",
    "NE_tally.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NorthEast Region\n",
    "Mid-Atlantic Divsion 2 (New Jersey, New York, and Pennsylvania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF based on Mid Atlantic Divsion\n",
    "mid_atlantic = usa[(usa['state_name']==\"New Jersey\") | (usa['state_name'] == 'New York') |\n",
    "                      (usa['state_name'] == 'Pennsylvania')]\n",
    "mid_atlantic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO ADD CASE TALLY TO MID ATLANTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing case count for Mid Atlantic Region\n",
    "# Groupby to consolidate cases by entire region\n",
    "mid_group = mid_atlantic.groupby([\"datetime\"])\n",
    "mid_sum = mid_group[\"cases\"].sum()\n",
    "\n",
    "# merge output of above groupbys to create new df\n",
    "mid_new =mid_atlantic.merge(mid_sum, on = \"datetime\")\n",
    "# Rename columns and sort by date\n",
    "mid_new = mid_new.rename(columns={\"cases_y\": \"reg_sum_cases\"}) \n",
    "mid_new.sort_values(by =\"datetime\")\n",
    "\n",
    "# Perform groupby operations to sum cases by day\n",
    "mid_tally =mid_new.groupby(['date', 'reg_sum_cases']).sum()\n",
    "mid_tally = mid_tally.reset_index()\n",
    "mid_tally.head(5)\n",
    "\n",
    "# now finsh date time conversion\n",
    "mid_tally['datetime'] = pd.to_datetime(mid_tally['date'])\n",
    "mid_tally[\"day\"] = mid_tally['datetime'].map(lambda x: x.day)\n",
    "mid_tally[\"month\"] = mid_tally['datetime'].map(lambda x: x.month)\n",
    "mid_tally[\"year\"] = mid_tally['datetime'].map(lambda x: x.year)\n",
    "mid_tally.sample(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midwest Region\n",
    "Division 3: East North Central (Illinois, Indiana, Michigan, Ohio, and Wisconsin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created DF based East North Central Divsion\n",
    "east_north_central = usa[(usa['state_name']=='Illinois') | (usa['state_name'] == 'Indiana') |\n",
    "                      (usa['state_name'] == 'Michigan') | (usa['state_name'] == 'Ohio') | \\\n",
    "                     (usa['state_name']=='Wisconsin')]\n",
    "east_north_central.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR ADDING TALLY COUNT CASE EAST NORTH CENTRAL DIVSION (STILL WORKING ON THIS ONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing case count for Mid Atlantic Region\n",
    "# Groupby to consolidate cases by entire region\n",
    "ENC_group = east_north_central.groupby([\"datetime\"])\n",
    "ENC_sum = ENC_group[\"cases\"].sum()\n",
    "\n",
    "# merge output of above groupbys to create new df\n",
    "east_north_central_new =east_north_central.merge(ENC_sum, on = \"datetime\")\n",
    "# Rename columns and sort by date\n",
    "east_north_central_new = east_north_central_new.rename(columns={\"cases_y\": \"reg_sum_cases\"}) \n",
    "east_north_central_new.sort_values(by =\"datetime\")\n",
    "\n",
    "# Perform groupby operations to sum cases by day\n",
    "east_north_central_tally =east_north_central(['date', 'reg_sum_cases']).sum()\n",
    "east_north_central_tally = east_north_central_tally.reset_index()\n",
    "east_north_central_tally(5)\n",
    "\n",
    "# now finsh date time conversion\n",
    "east_north_central_tally['datetime'] = pd.to_datetime(east_north_central_tally['date'])\n",
    "\n",
    "east_north_central_tally[\"day\"] = east_north_central_tally['datetime'].map(lambda x: x.day)\n",
    "east_north_central_tally[\"month\"] = east_north_central_tally['datetime'].map(lambda x: x.month)\n",
    "east_north_central_tally[\"year\"] = east_north_central_tally['datetime'].map(lambda x: x.year)\n",
    "east_north_central_tally.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " West North Central Divsion 4 (Iowa, Kansas, Minnesota, Missouri, Nebraska, North Dakota, and South Dakota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat DF for just West North Central\n",
    "west_northern_central =  usa[(usa['state_name']=='Iowa') | (usa['state_name'] == 'Kansas') |\n",
    "                      (usa['state_name'] == 'Minnesota') | (usa['state_name'] == 'Missouri') | \n",
    "                     (usa['state_name']=='North Dakota') | (usa['state_name']=='South Dakota')] \n",
    "\n",
    "west_northern_central.head()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function\n",
    "def make_regions(a,b,c,d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Division 5: South Atlantic (Delaware, Florida, Georgia, Maryland, North Carolina, South Carolina, Virginia, District of Columbia, and West Virginia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Df for just South Atlantic divsion.\n",
    "\n",
    "south_atlantic = usa[(usa['state_name']=='Delaware') | (usa['state_name'] == 'Flordia') |\n",
    "                      (usa['state_name'] == 'Georgia') | (usa['state_name'] == 'Maryland') | \n",
    "                     (usa['state_name']=='North Carolina') | (usa['state_name']=='South Carolina') |\n",
    "                     (usa['state_name']=='Virginia') | (usa['state_name']== 'District of Columbia') |\n",
    "                    (usa['state_name'] == 'West Virginia')]\n",
    "south_atlantic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Division 6: East South Central (Alabama, Kentucky, Mississippi, and Tennessee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF for just East South Central Divsion\n",
    "east_south_central =  usa[(usa['state_name']=='Alabama') | (usa['state_name'] == 'Kentucky') |\n",
    "                      (usa['state_name'] == 'Mississippi') | (usa['state_name'] == 'Tennessee')] \n",
    "\n",
    "east_south_central.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Division 7: West South Central (Arkansas, Louisiana, Oklahoma, and Texas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_northern_central =  usa[(usa['state_name']=='Arkansas') | (usa['state_name'] == 'Louisiana') |\n",
    "                      (usa['state_name'] == 'Oklahoma') | (usa['state_name'] == 'Texas') ] \n",
    "\n",
    "west_northern_central.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "West \n",
    "Mountain Divsion 8 (Arizona, Colorado, Idaho, Montana, Nevada, New Mexico, Utah, and Wyoming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DF for just Mountain divsion\n",
    "mountain =  usa[(usa['state_name']=='Arizona') | (usa['state_name'] == 'Colorado') |\n",
    "                      (usa['state_name'] == 'Idaho') | (usa['state_name'] == 'Montana') | \n",
    "                     (usa['state_name']=='Nevada') | (usa['state_name']=='New Mexico') |\n",
    "                     (usa['state_name']=='Utah') | (usa['state_name']== 'Wyoming') ]\n",
    "\n",
    "mountain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacific Divsion- with combined daily cases counts\n",
    "West Pacific (Alaska, California, Hawaii, Oregon, and Washington)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DF for just Pacific Divsion\n",
    "pacific =  usa[(usa['state_name']=='California') | (usa['state_name'] == 'Hawaii') |\n",
    "                      (usa['state_name'] == 'Oregon') | (usa['state_name'] == 'Washington') |\n",
    "                      (usa['state_name']=='Alaska')]\n",
    "\n",
    "pacific.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform operations to tally the daily case count in divsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing case count for Pacific Region\n",
    "# Groupby to consolidate cases by entire region\n",
    "pacific_group = pacific.groupby([\"datetime\"])\n",
    "pacific_sum = pacific_group[\"cases\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge output of above groupbys to create new df\n",
    "pacific_new = pacific.merge(pacific_sum, on = \"datetime\")\n",
    "pacific_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and sort by date\n",
    "pacific_new = pacific_new.rename(columns={\"cases_y\": \"reg_sum_cases\"})\n",
    "pacific_new.sort_values(by =\"datetime\")\n",
    "pacific_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform groupby operations to sum cases by day\n",
    "pacific_tally =pacific_new.groupby(['date', 'reg_sum_cases']).sum()\n",
    "pacific_tally = daily_count.reset_index()\n",
    "pacific_tally.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finsh date time conversion\n",
    "pacific_tally['datetime'] = pd.to_datetime(daily_count['date'])\n",
    "pacific_tally[\"day\"] = daily_count['datetime'].map(lambda x: x.day)\n",
    "pacific_tally[\"month\"] = daily_count['datetime'].map(lambda x: x.month)\n",
    "pacific_tally[\"year\"] = daily_count['datetime'].map(lambda x: x.year)\n",
    "pacific_tally.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
